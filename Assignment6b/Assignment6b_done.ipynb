{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Programming Exercise 6: Support Vector Machines\n",
    "============\n",
    "\n",
    "In this exercise, you will be using support vector machines (SVMs) to build a spam classifier. Before starting on the programming exercise, we strongly recommend watching the video lectures and completing the review questions for the associated topics. The files included in this Exercise are:  \n",
    "\n",
    "- spamTrain.mat - Spam training set\n",
    "- spamTest.mat - Spam test set\n",
    "- emailSample1.txt - Sample email 1\n",
    "- emailSample2.txt - Sample email 2\n",
    "- spamSample1.txt - Sample spam 1\n",
    "- spamSample2.txt - Sample spam 2\n",
    "- vocab.txt - Vocabulary list\n",
    "- getVocabList.m - Load vocabulary list\n",
    "- porterStemmer.m - Stemming function\n",
    "- readFile.m - Reads a file into a character string\n",
    "\n",
    "You only have to implement these two functions: \n",
    "\n",
    "- emailFeatures.m - Feature extraction from emails\n",
    "- processEmail.m - Email preprocessing\n",
    "\n",
    "The contained files are found in File ==> Open or in the readonly section of Assignment6b in the home page. We highly recommend that you take a look at them as you make progress in this exercise. \n",
    "\n",
    "### NOTE:\n",
    "\n",
    "You will find cells which contain the comment % GRADED FUNCTION: functionName. Do not edit that comment. Those cells will be used to grade your assignment. Each block of code with that comment should only have the function. \n",
    "\n",
    "Instructions will be provided as needed in the exercise. \n",
    "\n",
    "\n",
    "#### After submitting your assignment, you can [check your grades here](https://www.coursera.org/learn/machine-learning/programming/jbLrz/svm-on-spam-email). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spam Classification\n",
    "===================\n",
    "\n",
    "Many email services today provide spam filters that are able to classify\n",
    "emails into spam and non-spam email with high accuracy. In here you will use SVMs to build your own spam filter!\n",
    "\n",
    "You will be training a classifier to classify whether a given email,\n",
    "$x$, is spam ($y=1$) or non-spam ($y=0$). In particular, you need to\n",
    "convert each email into a feature vector $x \\in \\mathbb{R}^n$. The\n",
    "following parts of the exercise will walk you through how such a feature\n",
    "vector can be constructed from an email.\n",
    "\n",
    "The dataset included for this exercise is based on a\n",
    "a subset of the SpamAssassin Public Corpus. For the purpose of this\n",
    "exercise, you will only be using the body of the email (excluding the\n",
    "email headers).\n",
    "\n",
    "Preprocessing Emails\n",
    "--------------------\n",
    "\n",
    "<table border = \"0\" width = \"600\"><tr><td> \n",
    "\n",
    "> Anyone knows how much it costs to host a web portal ? <br \n",
    "/> > <br\n",
    "/>Well, it depends on how many visitors you're expecting.\n",
    "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
    "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
    "if you’re running something big.. <br \n",
    "/> <br\n",
    "\n",
    "/> To unsubscribe yourself from this mailing list, send an email to:\n",
    "groupname-unsubscribe@egroups.com\n",
    "\n",
    "<caption><center>Spam Email</center></caption>\n",
    "\n",
    "</td></tr></table>\n",
    "\n",
    "Before starting on a machine learning task, it is usually insightful to take a look at examples from the dataset. The email displayed above shows a sample email that contains a URL, an email address (at the end), numbers, and dollar amounts. While many emails would contain similar types of entities (e.g., numbers, other URLs, or other email addresses), the specific entities (e.g., the specific URL or specific dollar amount) will be different in almost every email. Therefore, one method often employed in processing emails is to “normalize” these values, so that all URLs are treated the same, all numbers are treated the same, etc. For example, we could replace each URL in the email with the unique string “httpaddr” to indicate that a URL was present. This has the effect of letting the spam classifier make a classification\n",
    "decision based on whether *any* URL was present, rather than whether a\n",
    "specific URL was present. This typically improves the performance of a\n",
    "spam classifier, since spammers often randomize the URLs, and thus the\n",
    "odds of seeing any particular URL again in a new piece of spam is very\n",
    "small.\n",
    "\n",
    "In **processEmail**, we have implemented the following email\n",
    "preprocessing and normalization steps:\n",
    "\n",
    "-   **Lower-casing:** The entire email is converted into lower case, so\n",
    "    that captialization is ignored (e.g., IndIcaTE is treated the\n",
    "    same way as Indicate.\n",
    "\n",
    "-   **Stripping HTML:** All HTML tags are removed from the emails. Many\n",
    "    emails often come with HTML formatting; we remove all the HTML tags,\n",
    "    so that only the content remains.\n",
    "\n",
    "-   **Normalizing URLs:** All URLs are replaced with the text\n",
    "    “*httpaddr*”.\n",
    "\n",
    "-   **Normalizing Email Addresses:** All email addresses are replaced\n",
    "    with the text “*emailaddr*”.\n",
    "\n",
    "-   **Normalizing Numbers:** All numbers are replaced with the text\n",
    "    “*number*”.\n",
    "\n",
    "-   **Normalizing Dollars:** All dollar signs (\\$) are replaced with the\n",
    "    text “*dollar*”.\n",
    "\n",
    "-   **Word Stemming:** Words are reduced to their stemmed form. For\n",
    "    example, “discount”, “discounts”, “discounted” and “discounting” are\n",
    "    all replaced with “*discount*”. Sometimes, the Stemmer actually\n",
    "    strips off additional characters from the end, so “include”,\n",
    "    “includes”, “included”, and “including” are all replaced with\n",
    "    “*includ*”.\n",
    "\n",
    "-   **Removal of non-words:** Non-words and punctuation have been\n",
    "    removed. All white spaces (tabs, newlines, spaces) have all been\n",
    "    trimmed to a single space character.\n",
    "\n",
    "The result of these preprocessing steps is shown below.\n",
    "While preprocessing has left word fragments and non-words, this form turns out\n",
    "to be much easier to work with for performing feature extraction.\n",
    "\n",
    "<table border = \"0\" width = \"600\"><tr><td> \n",
    "\n",
    "anyon know how much it cost to host a web portal well it depend on how mani \n",
    "visitor your expect thi can be anywher from less than number buck a month to \n",
    "a coupl of dollarnumb you should checkout httpaddr or perhap amazon ecnumb if \n",
    "your run someth big to unsubscrib yourself from thi mail list send an email \n",
    "to emailaddr  \n",
    "\n",
    "<caption><center>Processed Spam Email</center></caption>\n",
    "\n",
    "</td></tr></table>\n",
    "\n",
    "Vocabulary List\n",
    "--------------------\n",
    "<table border = \"0\" width = \"75\" ><tr><td> \n",
    "\n",
    "1 aa <br\n",
    "/> 2 ab <br\n",
    "/> 3 abil <br\n",
    "/> ... <br\n",
    "/> 86 anyon <br\n",
    "/> ... <br\n",
    "/> 86 anyon <br\n",
    "/> 916 know <br\n",
    "/> ... <br\n",
    "/> 1898 zero <br\n",
    "/> 1899 zip\n",
    "<caption><center>Vocab List</center></caption>\n",
    "\n",
    "</td></tr></table>\n",
    "\n",
    "\n",
    "After preprocessing the emails, we have a list of words (e.g., Vocab List) for each email. The next step is to choose which words we would like to use in our classifier and which we would want to leave out.\n",
    "For this exercise, we have chosen only the most frequently occuring words in the email as our set of words to be considered (the vocabulary list). Since words that occur rarely in the training set are only in a few emails, they might cause the model to overfit our training set. The complete vocabulary list is in the file **vocab.txt** but the Vocab List above shows you what it looks like. Our vocabulary list was selected by choosing all words which occur at least a 100 times in the spam corpus, resulting in a list of 1899 words. In practice, a vocabulary list with about 10,000 to 50,000 words is often used.\n",
    "\n",
    "<table border = \"0\" width = \"160\" ><tr><td> \n",
    "\n",
    "86 916 794 1077 883 370 1699 790 1822 1831 883 431 1171 794 1002 1893 1364 592 1676 238 162 89 688 945 1663 1120 1062 1699 375 1162 479 1893 1510 799 1182 1237 810 1895 1440 1547 181 1699 1758 1896 688 1676 992 961 1477 71 530 1699 531 <br \n",
    "/> \n",
    "\n",
    "<caption><center>Word Indices for Sample Email</center></caption>\n",
    "\n",
    "</td></tr></table>\n",
    "Given the vocabulary list, we can now map each word in the Processed emails (similar to the one found above) into a list of word indices that contains the index of the word in the vocabulary list. *Word Indices for Sample Email* shows the mapping for the sample email. Specifically, in the sample email, the word “anyone” was first normalized to “anyon” and then mapped onto the index 86 in the vocabulary list.\n",
    "Your task now is to complete the code in *processEmail* to perform this mapping. \n",
    "\n",
    "In the code below, you are given a string **str** which is a single word from the processed email. You should look up the word in the vocabulary list, **vocabList**, and find if the word exists in the vocabulary list. If the word exists, you should add the index of the word into the word indices variable. If the word does not exist, and is therefore not in the vocabulary, you can skip the word.\n",
    "Once you have implemented processEmail, then you will run your code on the email sample and you should get a vocabulary list along with the indices. \n",
    "\n",
    "#### Implementation\n",
    "\n",
    "To use an SVM to classify emails into Spam v.s. Non-Spam, you first need to convert each email into a vector of features. In this part, you will implement the preprocessing steps for each email. You should complete the code in the function below to produce a word indices vector for a given email. \n",
    "\n",
    "In Octave/MATLAB, you can compare two strings with the strcmp function. For example, strcmp(str1, str2) will return 1 only when both strings are equal. In the provided starter code, vocabList is a “cell-array” containing the words in the vocabulary. In Octave/MATLAB, a cell-array is just like a normal array (i.e., a vector), except that its elements can also be strings (which they can’t in a normal Octave/MATLAB matrix/vector), and you index into them using curly braces instead of square brackets. Specifically, to get the word at index i, you can use vocabList{i}. You can also use length(vocabList) to get the number of words in the vocabulary.\n",
    "\n",
    "\n",
    "word_indices = **processEmail**(email_contents) preprocesses the body of an email and returns a list of indices of the     words contained in the email.  \n",
    "\n",
    "Fill in this function (in your code here) to add the index of str to word_indices if it is in the vocabulary. At this point of the code, you have a stemmed word from the email in the variable str. You should look up str in the vocabulary list (vocabList). If a match exists, you should add the index of the word to the word_indices vector. Concretely, if str = 'action', then you should look up the vocabulary list to find where in vocabList 'action' appears. For example, if vocabList{18} = 'action', then, you should add 18 to the word_indices  vector (e.g., word_indices = [word_indices ; 18]; ). **vocabList{idx}** returns a the word with index idx in the\n",
    "vocabulary list. You can use strcmp(str1, str2) to compare two strings (str1 and\n",
    "str2). It will return 1 only if the two strings are equivalent.\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: processEmail\n",
    "function word_indices = processEmail(email_contents)\n",
    "%PROCESSEMAIL preprocesses a the body of an email and\n",
    "%returns a list of word_indices \n",
    "%   word_indices = PROCESSEMAIL(email_contents) preprocesses \n",
    "%   the body of an email and returns a list of indices of the \n",
    "%   words contained in the email. \n",
    "%\n",
    "\n",
    "% Load Vocabulary\n",
    "vocabList = getVocabList();\n",
    "\n",
    "% Init return value\n",
    "word_indices = [];\n",
    "\n",
    "% ========================== Preprocess Email ===========================\n",
    "\n",
    "% Find the Headers ( \\n\\n and remove )\n",
    "% Uncomment the following lines if you are working with raw emails with the\n",
    "% full headers\n",
    "\n",
    "% hdrstart = strfind(email_contents, ([char(10) char(10)]));\n",
    "% email_contents = email_contents(hdrstart(1):end);\n",
    "\n",
    "% Lower case\n",
    "email_contents = lower(email_contents);\n",
    "\n",
    "% Strip all HTML\n",
    "% Looks for any expression that starts with < and ends with > and replace\n",
    "% and does not have any < or > in the tag it with a space\n",
    "email_contents = regexprep(email_contents, '<[^<>]+>', ' ');\n",
    "\n",
    "% Handle Numbers\n",
    "% Look for one or more characters between 0-9\n",
    "email_contents = regexprep(email_contents, '[0-9]+', 'number');\n",
    "\n",
    "% Handle URLS\n",
    "% Look for strings starting with http:// or https://\n",
    "email_contents = regexprep(email_contents, ...\n",
    "                           '(http|https)://[^\\s]*', 'httpaddr');\n",
    "\n",
    "% Handle Email Addresses\n",
    "% Look for strings with @ in the middle\n",
    "email_contents = regexprep(email_contents, '[^\\s]+@[^\\s]+', 'emailaddr');\n",
    "\n",
    "% Handle $ sign\n",
    "email_contents = regexprep(email_contents, '[$]+', 'dollar');\n",
    "\n",
    "\n",
    "% ========================== Tokenize Email ===========================\n",
    "\n",
    "% Output the email to screen as well\n",
    "fprintf('\\n==== Processed Email ====\\n\\n');\n",
    "\n",
    "% Process file\n",
    "l = 0;\n",
    "\n",
    "while ~isempty(email_contents)\n",
    "\n",
    "    % Tokenize and also get rid of any punctuation\n",
    "    [str, email_contents] = ...\n",
    "       strtok(email_contents, ...\n",
    "              [' @$/#.-:&*+=[]?!(){},''\">_<;%' char(10) char(13)]);\n",
    "   \n",
    "    % Remove any non alphanumeric characters\n",
    "    str = regexprep(str, '[^a-zA-Z0-9]', '');\n",
    "\n",
    "    % Stem the word \n",
    "    % (the porterStemmer sometimes has issues, so we use a try catch block)\n",
    "    try str = porterStemmer(strtrim(str)); \n",
    "    catch str = ''; continue;\n",
    "    end;\n",
    "\n",
    "    % Skip the word if it is too short\n",
    "    if length(str) < 1\n",
    "       continue;\n",
    "    end\n",
    "\n",
    "    % Look up the word in the dictionary and add to word_indices if\n",
    "    % found\n",
    "    % ====================== YOUR CODE HERE ======================\n",
    "    match = strcmp(str, vocabList);\n",
    "    if sum(match) > 0\n",
    "        word_indices(end+1,1) = find(match);\n",
    "    end\n",
    "%     for i = 1:size(vocabList,1),\n",
    "%       if strcmp(vocabList{i},str) == 1,\n",
    "%         word_indices = [word_indices; i];\n",
    "%       end\n",
    "%     end \n",
    "\n",
    "\n",
    "\n",
    "    % =============================================================\n",
    "\n",
    "\n",
    "    % Print to screen, ensuring that the output lines are not too long\n",
    "    if (l + length(str) + 1) > 78\n",
    "        fprintf('\\n');\n",
    "        l = 0;\n",
    "    end\n",
    "    fprintf('%s ', str);\n",
    "    l = l + length(str) + 1;\n",
    "\n",
    "end\n",
    "\n",
    "% Print footer\n",
    "fprintf('\\n\\n=========================\\n');\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processed Email ====\n",
      "\n",
      "anyon know how much it cost to host a web portal well it depend on how mani \n",
      "visitor you re expect thi can be anywher from less than number buck a month \n",
      "to a coupl of dollarnumb you should checkout httpaddr or perhap amazon ecnumb \n",
      "if your run someth big to unsubscrib yourself from thi mail list send an \n",
      "email to emailaddr \n",
      "\n",
      "=========================\n",
      "word_indices =\n",
      "\n",
      "     86\n",
      "    916\n",
      "    794\n",
      "   1077\n",
      "    883\n",
      "    370\n",
      "   1699\n",
      "    790\n",
      "   1822\n",
      "   1831\n",
      "    883\n",
      "    431\n",
      "   1171\n",
      "    794\n",
      "   1002\n",
      "   1893\n",
      "   1364\n",
      "    592\n",
      "   1676\n",
      "    238\n",
      "    162\n",
      "     89\n",
      "    688\n",
      "    945\n",
      "   1663\n",
      "   1120\n",
      "   1062\n",
      "   1699\n",
      "    375\n",
      "   1162\n",
      "    479\n",
      "   1893\n",
      "   1510\n",
      "    799\n",
      "   1182\n",
      "   1237\n",
      "    810\n",
      "   1895\n",
      "   1440\n",
      "   1547\n",
      "    181\n",
      "   1699\n",
      "   1758\n",
      "   1896\n",
      "    688\n",
      "   1676\n",
      "    992\n",
      "    961\n",
      "   1477\n",
      "     71\n",
      "    530\n",
      "   1699\n",
      "    531\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warning('off'); addpath('../../readonly/Assignment6b/');\n",
    "file_contents = readFile('emailSample1.txt');     % Extract Features\n",
    "word_indices  = processEmail(file_contents);\n",
    "word_indices % == [86 916 794 1077 883 370 1699 790 1822 1831 883 431 1171 794 1002 1893 1364 592 1676 238 162 89 688 945 1663 1120 1062 1699 375 1162 479 1893 1510 799 1182 1237 810 1895 1440 1547 181 1699 1758 1896 688 1676 992 961 1477 71 530 1699 531]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "*Word Indices for Sample Email* found in tables above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting Features from Emails\n",
    "-------------------------------\n",
    "\n",
    "You will now implement the feature extraction that converts each email\n",
    "into a vector in $\\mathbb{R}^n$. For this exercise, you will be using\n",
    "$n=$ \\# words in vocabulary list. Specifically, the feature\n",
    "$x_i \\in \\{0,1\\}$ for an email corresponds to whether the $i$-th word in\n",
    "the dictionary occurs in the email. That is, $x_i=1$ if the $i$-th word\n",
    "is in the email and $x_i=0$ if the $i$-th word is not present in the\n",
    "email.\n",
    "\n",
    "Thus, for a typical email, this feature would look like:\n",
    "\n",
    "$$x = \\begin{bmatrix} \n",
    "0 \\\\\n",
    "\\vdots \\\\ \n",
    "1 \\\\\n",
    "0 \\\\\n",
    "\\vdots \\\\ \n",
    "1  \\\\\n",
    "0 \\\\ \n",
    "\\vdots \\\\ \n",
    "0 \n",
    "\\end{bmatrix} \\in \\mathbb{R}^n.$$\n",
    "\n",
    "You should now complete the code in **emailFeatures** to generate a\n",
    "feature vector for an email, given the *word_indices*. Once you have implemented **emailFeatures**, we will run your code on the email sample. \n",
    "\n",
    "**Implementation**: \n",
    "\n",
    "x = emailFeatures(word_indices) takes in a word_indices vector and produces a feature vector from the word indices. \n",
    "\n",
    "Fill in the function to return a feature vector for the given email (word_indices). To help make it easier to  process the emails, we have have already pre-processed each email and converted each word in the email into an index in a fixed dictionary (of 1899 words). The variable word_indices contains the list of indices of the words which occur in one email.\n",
    "\n",
    "For example, if an email has the text:\n",
    "\n",
    " - The quick brown fox jumped over the lazy dog.\n",
    "\n",
    "Then, the word_indices vector for this text might look like:\n",
    "              \n",
    " - 60  100   33   44   10     53  60  58   5\n",
    "\n",
    "where, we have mapped each word onto a number, for example:\n",
    "\n",
    "- the   -- 60\n",
    "- quick -- 100\n",
    "- ...\n",
    "\n",
    "(note: the above numbers are just an example and are not the actual mappings).\n",
    "\n",
    "Your task is take one such word_indices vector and construct a binary feature vector that indicates whether a particular word occurs in the email. That is, x(i) = 1 when word i is present in the email. Concretely, if the word 'the' (say, index 60) appears in the email, then x(60) = 1. The feature vector should look like:\n",
    "\n",
    "- x = [ 0 0 0 0 1 0 0 0 ... 0 0 0 0 1 ... 0 0 0 1 0 ..];\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: emailFeatures\n",
    "function x = emailFeatures(word_indices)\n",
    "\n",
    "n = 1899;                   % Total number of words in the dictionary\n",
    "\n",
    "x = zeros(n, 1);            % You need to return the following variable correctly.\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "% for w = 1:length(word_indices)\n",
    "%     word = word_indices(w);\n",
    "%     x(word,1) = x(word,1) + 1;\n",
    "% end\n",
    "x(word_indices) = 1;\n",
    "\n",
    "% =============================================================\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processed Email ====\n",
      "\n",
      "anyon know how much it cost to host a web portal well it depend on how mani \n",
      "visitor you re expect thi can be anywher from less than number buck a month \n",
      "to a coupl of dollarnumb you should checkout httpaddr or perhap amazon ecnumb \n",
      "if your run someth big to unsubscrib yourself from thi mail list send an \n",
      "email to emailaddr \n",
      "\n",
      "=========================\n",
      "Length of feature vector: 1899\n",
      "Number of non-zero entries: 45\n"
     ]
    }
   ],
   "source": [
    "file_contents = readFile('emailSample1.txt');      % Extract Features\n",
    "word_indices  = processEmail(file_contents);\n",
    "features      = emailFeatures(word_indices);\n",
    "\n",
    "% Print Stats\n",
    "fprintf('Length of feature vector: %d\\n', length(features));\n",
    "fprintf('Number of non-zero entries: %d\\n', sum(features > 0));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "Length of feature vector: 1899\n",
    "\n",
    "Number of non-zero entries: 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training SVM for Spam Classification\n",
    "------------------------------------\n",
    "\n",
    "After you have completed the feature extraction functions, the next step\n",
    "of will load a preprocessed training dataset that\n",
    "will be used to train a SVM classifier. **spamTrain.mat** contains\n",
    "4000 training examples of spam and non-spam email, while\n",
    "**spamTest.mat** contains 1000 test examples. Each original email was\n",
    "processed using the **processEmail** and **emailFeatures**\n",
    "functions and converted into a vector $x^{(i)} \\in \\mathbb{R}^{1899}$.\n",
    "\n",
    "After loading the dataset, we will proceed to train a\n",
    "SVM to classify between spam ($y=1$) and non-spam ($y=0$) emails. This might take 1 to 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training ......................................................................\n",
      "...............................................................................\n",
      "...............................................................................\n",
      "... Done! \n",
      "\n",
      "Accuracy =  99.825\n"
     ]
    }
   ],
   "source": [
    "load('spamTrain.mat');     % Load the Spam Email dataset to get X and y in you rdataset\n",
    "\n",
    "C = 0.1;                   % Cost \n",
    "model = svmTrain(X, y, C, @linearKernel);\n",
    "\n",
    "p = svmPredict(model, X);\n",
    "\n",
    "Accuracy = mean(double(p == y)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "Accuracy $\\approx$  99.8 %\n",
    "\n",
    "Now that we have trained our classifier, we will proceed to evaluate it on a test set. This might take 1 to 2 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  98.900\n"
     ]
    }
   ],
   "source": [
    "load('spamTest.mat');          % You will have Xtest, ytest in your environment\n",
    "\n",
    "p = svmPredict(model, Xtest);\n",
    "\n",
    "Accuracy =  mean(double(p == ytest)) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**\n",
    "\n",
    "Accuracy $\\approx$  98%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top Predictors for Spam\n",
    "-----------------------\n",
    "\n",
    "<table border = \"0\" width = \"550\" ><tr><td> \n",
    "<center>\n",
    " our click  remov  guarante visit  basenumb dollar will price pleas most lo nbsp ga da </center> <br /> \n",
    "<caption><center>Top Predictors for Spam Email</center></caption>\n",
    "</td></tr></table>\n",
    "\n",
    "To better understand how the spam classifier works, we can inspect the\n",
    "parameters to see which words the classifier thinks are the most\n",
    "predictive of spam. The next step below finds the\n",
    "parameters with the largest positive values in the classifier and\n",
    "displays the corresponding words in the box above. Thus, if an\n",
    "email contains words such as “guarantee”, “remove”, “dollar”, and\n",
    "“price” (the top predictors above), it is\n",
    "likely to be classified as spam.\n",
    "\n",
    "**Implementation** \n",
    "\n",
    "Since the model we are training is a linear SVM, we can inspect the \n",
    "weights learned by the model to understand better how it is determining \n",
    "whether an email is spam or not. The following code finds the words with \n",
    "the highest weights in the classifier. Informally, the classifier \n",
    "'thinks' that these words are the most likely indicators of spam.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top predictors of spam: \n",
      " our             (0.503380) \n",
      " click           (0.467845) \n",
      " remov           (0.416106) \n",
      " guarante        (0.384495) \n",
      " visit           (0.367830) \n",
      " basenumb        (0.349906) \n",
      " dollar          (0.322995) \n",
      " will            (0.271084) \n",
      " price           (0.267594) \n",
      " nbsp            (0.260645) \n",
      " pleas           (0.259834) \n",
      " most            (0.259631) \n",
      " lo              (0.256661) \n",
      " ga              (0.247400) \n",
      " hour            (0.242709) \n"
     ]
    }
   ],
   "source": [
    "[weight, idx] = sort(model.w, 'descend');           % Sort the weights and obtin the vocabulary list\n",
    "vocabList = getVocabList();\n",
    "\n",
    "fprintf('\\nTop predictors of spam: \\n');\n",
    "for i = 1:15\n",
    "    fprintf(' %-15s (%f) \\n', vocabList{idx(i)}, weight(i));\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional (ungraded) exercise: Try your own emails\n",
    "-------------------------------------------------\n",
    "\n",
    "Now that you have trained a spam classifier, you can start trying it out\n",
    "on your own emails. In the starter code, we have included two email\n",
    "examples (*emailSample1.txt* and *emailSample2.txt*) and two\n",
    "spam examples (*spamSample1.txt* and *spamSample2.txt*). The\n",
    "last part below runs the spam classifier over the first\n",
    "spam example and classifies it using the learned SVM. You should now try\n",
    "the other examples we have provided and see if the classifier gets them\n",
    "right. You can also try your own emails by replacing the examples (plain\n",
    "text files) with your own emails.\n",
    "\n",
    "To add them, click File ==> Open , and upload them. \n",
    "\n",
    "\n",
    "In the starter code, we have included *spamSample1.txt*, *spamSample2.txt*, *emailSample1.txt* and *emailSample2.txt* as examples. The following code reads in one of these emails and then uses your learned SVM classifier to determine whether the email is Spam or Not Spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Processed Email ====\n",
      "\n",
      "do you want to make dollarnumb or more per week if you ar a motiv and qualifi \n",
      "individu i will person demonstr to you a system that will make you dollarnumb \n",
      "number per week or more thi is not mlm call our number hour pre record number \n",
      "to get the detail number number number i need peopl who want to make seriou \n",
      "monei make the call and get the fact invest number minut in yourself now \n",
      "number number number look forward to your call and i will introduc you to \n",
      "peopl like yourself who ar current make dollarnumb number plu per week number \n",
      "number number numberljgvnumb numberleannumberlrmsnumb \n",
      "numberwxhonumberqiytnumb numberrjuvnumberhqcfnumb numbereidbnumberdmtvlnumb \n",
      "\n",
      "=========================\n",
      "\n",
      "Processed spamSample1.txt\n",
      "\n",
      "Spam Classification: 1\n",
      "(1 indicates spam, 0 indicates not spam)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "% Set the file to be read in (change this to spamSample2.txt,\n",
    "% emailSample1.txt or emailSample2.txt to see different predictions on\n",
    "% different emails types). Try your own emails as well!\n",
    "filename = 'spamSample1.txt';\n",
    "\n",
    "% Read and predict\n",
    "file_contents = readFile(filename);\n",
    "word_indices  = processEmail(file_contents);\n",
    "x             = emailFeatures(word_indices);\n",
    "p = svmPredict(model, x);\n",
    "\n",
    "fprintf('\\nProcessed %s\\n\\nSpam Classification: %d\\n', filename, p);\n",
    "fprintf('(1 indicates spam, 0 indicates not spam)\\n\\n');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional (ungraded) exercise: Build your own dataset\n",
    "----------------------------------------------------\n",
    "\n",
    "In this exercise, we provided a preprocessed training set and test set.\n",
    "These datasets were created using the same functions\n",
    "*processEmail* and *emailFeatures* that you now have\n",
    "completed. For this optional (ungraded) exercise, you will build your\n",
    "own dataset using the original emails from the [SpamAssassin Public\n",
    "Corpus].\n",
    "\n",
    "Your task in this optional (ungraded) exercise is to download the\n",
    "original files from the public corpus and extract them. After extracting\n",
    "them, you should run the processEmail and\n",
    "emailFeatures functions on each email to extract a feature vector\n",
    "from each email. This will allow you to build a dataset $X$, $y$ of\n",
    "examples. You should then randomly divide up the dataset into a training\n",
    "set, a cross validation set and a test set.\n",
    "\n",
    "While you are building your own dataset, we also encourage you to try\n",
    "building your own vocabulary list (by selecting the high frequency words\n",
    "that occur in the dataset) and adding any additional features that you\n",
    "think might be useful.\n",
    "\n",
    "**Note:**  The original emails will have email headers that you might wish to leave out. We have included code in *processEmail* that will help you remove these headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Your code below - Optional\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "machine-learning",
   "graded_item_id": "jbLrz",
   "launcher_item_id": "RD616",
   "submission_attachments": [
    "computeCost.m",
    "computeCostMulti.m",
    "featureNormalize.m",
    "gradientDescent.m",
    "gradientDescentMulti.m",
    "normalEqn.m",
    "plotData.m",
    "warmUpExercise.m"
   ]
  },
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
