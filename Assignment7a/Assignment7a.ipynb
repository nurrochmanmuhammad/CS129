{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Programming Exercise 7: K-means Clustering \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you will implement the K-means clustering algorithm and apply it to compress an image. In the second part, you will use principal component analysis to find a low-dimensional representation of face images. Before starting on the programming exercise, we strongly recommend watching the video lectures and completing the review questions for the associated topics. We have included one function for you in this exercise: \n",
    "\n",
    "- runkMeans\n",
    "\n",
    "You only have to implement these two functions:\n",
    "\n",
    "- computeCentroids\n",
    "- findClosestCentroids\n",
    "\n",
    "The contained files are found in File ==> Open... We highly recommend that you take a look at them as you make progress in this exercise. \n",
    "\n",
    "### NOTE:\n",
    "\n",
    "You will find cells which contain the comment % GRADED FUNCTION: functionName. Do not edit that comment. Those cells will be used to grade your assignment. Each block of code with that comment should only have the function. \n",
    "\n",
    "Instructions will be provided as needed in the exercise. \n",
    "\n",
    "\n",
    "#### When you are done and submit the assignment, click here to check your [submission](https://www.coursera.org/learn/ml-test-jupyter/programming/J2ipZ). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means Clustering\n",
    "====================\n",
    "\n",
    "In this this exercise, you will implement the $K$-means algorithm and\n",
    "use it for image compression. You will first start on an example 2D\n",
    "dataset that will help you gain an intuition of how the $K$-means\n",
    "algorithm works. After that, you wil use the $K$-means algorithm for\n",
    "image compression by reducing the number of colors that occur in an\n",
    "image to only those that are most common in that image. \n",
    "\n",
    "Implementing K-means\n",
    "----------------------\n",
    "\n",
    "The K-means algorithm is a method to automatically cluster similar\n",
    "data examples together. Concretely, you are given a training set\n",
    "$\\{x^{(1)}, ..., x^{(m)}\\}$ (where $x^{(i)} \\in \\mathbb{R}^n$), and want\n",
    "to group the data into a few cohesive “clusters”. The intuition behind\n",
    "$K$-means is an iterative procedure that starts by guessing the initial\n",
    "centroids, and then refines this guess by repeatedly assigning examples\n",
    "to their closest centroids and then recomputing the centroids based on\n",
    "the assignments.\n",
    "\n",
    "The $K$-means algorithm is as follows:\n",
    "\n",
    "``` {frame=\"single\"}\n",
    "% Initialize centroids\n",
    "centroids = kMeansInitCentroids(X, K);\n",
    "for iter = 1:iterations\n",
    "    % Cluster assignment step: Assign each data point to the \n",
    "    % closest centroid. idx(i) corresponds to c^(i), the index\n",
    "    % of the centroid assigned to example i\n",
    "    idx = findClosestCentroids(X, centroids);\n",
    "\n",
    "    % Move centroid step: Compute means based on centroid \n",
    "    % assignments\n",
    "    centroids = computeMeans(X, idx, K);\n",
    "end\n",
    "```\n",
    "\n",
    "The inner-loop of the algorithm repeatedly carries out two steps: (i)\n",
    "Assigning each training example $x^{(i)}$ to its closest centroid, and\n",
    "(ii) Recomputing the mean of each centroid using the points assigned to\n",
    "it. The $K$-means algorithm will always converge to some final set of\n",
    "means for the centroids. Note that the converged solution may not always\n",
    "be ideal and depends on the initial setting of the centroids. Therefore,\n",
    "in practice the $K$-means algorithm is usually run a few times with\n",
    "different random initializations. One way to choose between these\n",
    "different solutions from different random initializations is to choose\n",
    "the one with the lowest cost function value (distortion).\n",
    "\n",
    "You will implement the two phases of the $K$-means algorithm separately\n",
    "in the next sections. You will start by completing *findClosestCentroid* and then proceed to complete *computeCentroids*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding closest centroids\n",
    "\n",
    "In the “cluster assignment” phase of the $K$-means algorithm, the\n",
    "algorithm assigns every training example $x^{(i)}$ to its closest\n",
    "centroid, given the current positions of centroids. Specifically, for\n",
    "every example $i$ we set\n",
    "$$c^{(i)} := j \\quad \\mathrm{that \\; minimizes} \\quad ||x^{(i)} - \\mu_j||^2,$$\n",
    "where $c^{(i)}$ is the index of the centroid that is closest to\n",
    "$x^{(i)}$, and $\\mu_j$ is the position (value) of the $j$’th centroid.\n",
    "Note that $c^{(i)}$ corresponds to idx(i) in the starter code.\n",
    "\n",
    "Your task is to complete the code in findClosestCentroids. This\n",
    "function takes the data matrix $X$ and the locations of all\n",
    "centroids inside centroids and should output a one-dimensional\n",
    "array idx that holds the index (a value in $\\{1,...,K\\}$, where\n",
    "$K$ is total number of centroids) of the closest centroid to every\n",
    "training example.\n",
    "\n",
    "You can implement this using a loop over every training example and\n",
    "every centroid.\n",
    "Once you have completed the code in findClosestCentroids, run your code and you should see the output\n",
    "[1 3 2] corresponding to the centroid assignments for the first 3\n",
    "examples.\n",
    "\n",
    "**Implementation**:\n",
    "\n",
    "idx = **findClosestCentroids**(X, centroids) returns the closest centroids in idx for a dataset $X$ where each row is a single example. idx = m x 1  vector of centroid assignments (i.e. each entry in range $[1..K]$)\n",
    "\n",
    "Instructions: Go over every example, find its closest centroid, and store the index inside idx at the appropriate location. Concretely, idx(i) should contain the index of the centroid closest to example i. Hence, it should be a value in the range $1..K$\n",
    "\n",
    "**Note:** You can use a for-loop over the examples to compute this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: findClosestCentroids\n",
    "function idx = findClosestCentroids(X, centroids)\n",
    "\n",
    "K = size(centroids, 1);            % Set K\n",
    "idx = zeros(size(X,1), 1);         % Return the following variable correctly.\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whos\n",
    "load('ex7data2.mat');                % Load an example dataset that we will be using\n",
    "K = 3;                               % Select an initial set of centroids (3 Centroids)\n",
    "initial_centroids = [3 3; 6 2; 8 5];\n",
    "\n",
    "idx = findClosestCentroids(X, initial_centroids);       % find closest centroids using initial_centroids\n",
    "idx(1:3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "1 3 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing centroid means\n",
    "\n",
    "Given assignments of every point to a centroid, the second phase of the\n",
    "algorithm recomputes, for each centroid, the mean of the points that\n",
    "were assigned to it. Specifically, for every centroid $k$ we set\n",
    "$$\\mu_k := \\frac{1}{|C_k|} \\sum_{i \\in C_k} x^{(i)}$$ where $C_k$ is the\n",
    "set of examples that are assigned to centroid $k$. Concretely, if two\n",
    "examples say $x^{(3)}$ and $x^{(5)}$ are assigned to centroid $k=2$,\n",
    "then you should update $\\mu_2 = \\frac{1}{2}(x^{(3)}+x^{(5)})$.\n",
    "\n",
    "You should now complete the code in the function computeCentroids below. You can\n",
    "implement this function using a loop over the centroids. You can also\n",
    "use a loop over the examples; but if you can use a vectorized\n",
    "implementation that does not use such a loop, your code may run faster.\n",
    "\n",
    "Once you have completed the function computeCentroids below, you should run the cell below\n",
    "to output the centroids after\n",
    "the first step of $K$-means.\n",
    "\n",
    "**Implementation**: \n",
    "\n",
    "centroids = **computeCentroids(X, idx, K)** returns the new centroids by computing the means of the data points assigned to each centroid. It is given a dataset X where each row is a single data point, a vector idx of centroid assignments (i.e. each entry in range [1..K]) for each example, and K, the number of centroids. You should return a matrix centroids, where each row of centroids is the mean of the data points assigned to it.\n",
    "\n",
    "\n",
    "Go over every centroid and compute mean of all points that belong to it. Concretely, the row vector centroids(i, :) should contain the mean of the data points assigned to centroid i.\n",
    "\n",
    "Note: You can use a for-loop over the centroids to compute this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: computeCentroids\n",
    "function centroids = computeCentroids(X, idx, K)\n",
    "\n",
    "[m n] = size(X);                 % Useful variables\n",
    "centroids = zeros(K, n);         % Return the following variable correctly.\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% Compute means based on the closest centroids found in the previous part.\n",
    "centroids = computeCentroids(X, idx, K); \n",
    "\n",
    "centroids'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    " 2.4283   5.8135   7.1194\n",
    " \n",
    " 3.1579   2.6337   3.6167"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on example Dataset \n",
    "\n",
    "<img src=\"figure 1.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "After you have completed the two functions (*findClosestCentroids*\n",
    "and *computeCentroids*), the next step will run the\n",
    "$K$-means algorithm on a toy 2D dataset to help you understand how\n",
    "$K$-means works. We encourage you to take a look at the\n",
    "function to understand how it works. Notice that the code calls the two\n",
    "functions you implemented in a loop.\n",
    "\n",
    "When you run the next step, the $K$-means code will produce a\n",
    "visualization that steps you through the progress of the algorithm at\n",
    "each iteration. Run the second cell below multiple times to see how each step of the\n",
    "$K$-means algorithm changes the centroids and cluster assignments. At\n",
    "the end, your figure should look like the one displayed in Figure 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global max_iters = 1;                             % Keep track of which iteration you are on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fprintf('Running K-Means clustering on iteration number %d.\\n',max_iters);\n",
    "\n",
    "% Load an example dataset\n",
    "load('ex7data2.mat');\n",
    "initial_centroids = [3 3; 6 2; 8 5];\n",
    "K = 3;\n",
    "[centroids, idx] = runkMeans(X, initial_centroids, max_iters, true);\n",
    "max_iters++;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random initialization\n",
    "---------------------\n",
    "\n",
    "The initial assignments of centroids for the example dataset was designed so that you will see the same figure as in Figure 1. In practice, a good strategy for initializing the centroids is to select random examples from the\n",
    "training set.\n",
    "\n",
    "In this part of the exercise, you should understand how the function\n",
    "kMeansInitCentroids is implemented.\n",
    "\n",
    "The code first randomly permutes the indices of the examples\n",
    "(using *randperm*). Then, it selects the first $K$ examples based\n",
    "on the random permutation of the indices. This allows the examples to be\n",
    "selected at random without the risk of selecting the same example\n",
    "twice.\n",
    " \n",
    "centroids = **kMeansInitCentroids**(X, K) returns K initial centroids to be used with the K-Means on the dataset X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function centroids = kMeansInitCentroids(X, K)\n",
    "\n",
    "centroids = zeros(K, size(X, 2));    % Return this value correctly\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "\n",
    "randidx = randperm(size(X, 1));  % Randomly reorder the points\n",
    "centroids = X(randidx(1:K), :);  % Take the first K examples as centroids\n",
    "\n",
    "\n",
    "% =============================================================\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image compression with $K$-means\n",
    "--------------------------------\n",
    "\n",
    "<img src=\"figure 2.png\" width=\"500\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "Now, you will apply $K$-means to image compression. In a\n",
    "straightforward 24-bit color representation of an image, each pixel\n",
    "is represented as three 8-bit unsigned integers (ranging from 0 to 255)\n",
    "that specify the red, green and blue intensity values. This encoding is\n",
    "often refered to as the RGB encoding. Our image contains thousands of\n",
    "colors, and in this part of the exercise, you will reduce the number of\n",
    "colors to 16 colors.\n",
    "\n",
    "By making this reduction, it is possible to represent (compress) the\n",
    "photo in an efficient way. Specifically, you only need to store the RGB values of the 16 selected colors, and for each pixel in the image you now need to only store the index of the color at that location (where only 4 bits are necessary to represent 16 possibilities).\n",
    "\n",
    "In this part, you will use the K-means algorithm to select the 16 colors that will be used to represent the compressed image. Concretely, you will treat every pixel in the original image as a data example and use the K-means algorithm to find the 16 colors that best group (cluster) the pixels in the 3- dimensional RGB space. Once you have computed the cluster centroids on the image, you will then use the 16 colors to replace the pixels in the original image.\n",
    "\n",
    "\n",
    "### $K$-means on pixels\n",
    "\n",
    "In Octave/MATLAB, images can be read in as follows:\n",
    "\n",
    "\n",
    "``` {frame=\"single\"}\n",
    "% Load 128x128 color image (bird_small.png)\n",
    "A = imread('bird_small.png');\n",
    "\n",
    "% You will need to have installed the image package to used\n",
    "% imread. If you do not have the image package installed, you\n",
    "% should instead change the following line to\n",
    "% \n",
    "%   load('bird_small.mat'); % Loads the image into the variable A\n",
    "```\n",
    "\n",
    "This creates a three-dimensional matrix A whose first two indices\n",
    "identify a pixel position and whose last index represents red, green, or\n",
    "blue. For example, A(50, 33, 3) gives the blue intensity of the\n",
    "pixel at row 50 and column 33.\n",
    "\n",
    "The code first loads the image, and then reshapes it\n",
    "to create an $m \\times 3$ matrix of pixel colors (where\n",
    "$m=16384 = 128\\times128$), and calls your $K$-means function on it.\n",
    "\n",
    "After finding the top $K=16$ colors to represent the image, you can now\n",
    "assign each pixel position to its closest centroid using the\n",
    "findClosestCentroids function. This allows you to represent the\n",
    "original image using the centroid assignments of each pixel. Notice that\n",
    "you have significantly reduced the number of bits that are required to\n",
    "describe the image. The original image required 24 bits for each one of\n",
    "the $128\\times128$ pixel locations, resulting in total size of\n",
    "$128 \\times 128 \\times 24 = 393,216$ bits. The new representation\n",
    "requires some overhead storage in form of a dictionary of 16 colors,\n",
    "each of which require 24 bits, but the image itself then only requires 4\n",
    "bits per pixel location. The final number of bits used is therefore\n",
    "$16 \\times 24 + 128 \\times 128 \\times 4 = 65,920$ bits, which\n",
    "corresponds to compressing the original image by about a factor of 6.\n",
    "\n",
    "<img src=\"figure 3.png\" width=\"700\" height=\"700\">\n",
    "\n",
    "\n",
    "\n",
    "Finally, you can view the effects of the compression by reconstructing\n",
    "the image based only on the centroid assignments. Specifically, you can\n",
    "replace each pixel location with the mean of the centroid assigned to\n",
    "it. Figure 3 shows the reconstruction we obtained.\n",
    "Even though the resulting image retains most of the characteristics of\n",
    "the original, we also see some compression artifacts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Implementation**: \n",
    "\n",
    "In this exercise, you will use K-Means to compress an image. To do this, you will first run K-Means on the colors of the pixels in the image and then you will map each pixel on to it's closest centroid.\n",
    "\n",
    "Note: If imread does not work for you, you can try instead load ('bird_small.mat');. This might take 1 minute to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = double(imread('bird_small.png'));         %  Load an image of a bird\n",
    "A = A / 255;                                  %  Divide by 255 so that all values are in the range 0 - 1\n",
    "img_size = size(A);                           %  Size of the image\n",
    "\n",
    "% Reshape the image into an Nx3 matrix where N = number of pixels.\n",
    "% Each row will contain the Red, Green and Blue pixel values\n",
    "% This gives us our dataset matrix X that we will use K-Means on.\n",
    "X = reshape(A, img_size(1) * img_size(2), 3);\n",
    "\n",
    "K = 16;                        % Run your K-Means algorithm on this data\n",
    "max_iters = 10;                % You should try different values of K and max_iters here\n",
    "\n",
    "initial_centroids = kMeansInitCentroids(X, K); % Using the function you have implemented above. \n",
    "\n",
    "[centroids, idx] = runkMeans(X, initial_centroids, max_iters);  % Run K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will proceed to compress the image: \n",
    "\n",
    "In the code below we use closest clusters for each example. After that, we represent the image X as in terms of the indices in idx. We then recover the image from the indices (idx) by mapping each pixel (specified by it's index in idx) to the centroid value. Finally we reshape the recovered image into proper dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = findClosestCentroids(X, centroids);   % Find closest cluster members\n",
    "X_recovered = centroids(idx,:);             % Represent Image in terms of indices\n",
    "\n",
    "X_recovered = reshape(X_recovered, img_size(1), img_size(2), 3);  % Reshape recovered image into proper dimensions\n",
    "\n",
    "subplot(1, 2, 1);                           % Display the original image \n",
    "imagesc(A); \n",
    "title('Original');\n",
    "\n",
    "% Display compressed image side by side\n",
    "subplot(1, 2, 2);\n",
    "imagesc(X_recovered)\n",
    "title(sprintf('Compressed, with %d colors.', K));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional (ungraded) exercise: Use your own image\n",
    "------------------------------------------------\n",
    "\n",
    "In this exercise, modify the code we have supplied to run on one of your\n",
    "own images. Note that if your image is very large, then $K$-means can\n",
    "take a long time to run. Therefore, we recommend that you resize your\n",
    "images to managable sizes before running the code. You can also try to\n",
    "vary $K$ to see the effects on the compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% Compress your own image below !!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "ml-test-jupyter",
   "graded_item_id": "J2ipZ",
   "launcher_item_id": "bd3TA",
   "submission_attachments": [
    "computeCost.m",
    "computeCostMulti.m",
    "featureNormalize.m",
    "gradientDescent.m",
    "gradientDescentMulti.m",
    "normalEqn.m",
    "plotData.m",
    "warmUpExercise.m"
   ]
  },
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
