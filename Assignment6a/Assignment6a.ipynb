{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Programming Exercise 6: Support Vector Machines on Plots\n",
    "============\n",
    "\n",
    "In this exercise, you will be using support vector machines (SVMs) to build a spam classifier. Before starting on the programming exercise, we strongly recommend watching the video lectures and completing the review questions for the associated topics. The files included in this Exercise are: \n",
    "\n",
    "- ex6data1.mat - Example Dataset 1\n",
    "- ex6data2.mat - Example Dataset 2\n",
    "- ex6data3.mat - Example Dataset 3\n",
    "- svmTrain.m - SVM training function\n",
    "- svmPredict.m - SVM prediction function plotData.m \n",
    "- Plot 2D data visualizeBoundaryLinear.m \n",
    "- Plot linear boundary visualizeBoundary.m \n",
    "- Plot non-linear boundary linearKernel.m \n",
    "- Linear kernel for SVM\n",
    "\n",
    "You only have to implement these two functions:\n",
    "\n",
    "- gaussianKernel.m - Gaussian kernel for SVM \n",
    "- dataset3Params.m - Parameters to use for Dataset 3\n",
    "\n",
    "The contained files are found in File --> Open... We highly recommend that you take a look at them as you make progress in this exercise. \n",
    "\n",
    "### NOTE:\n",
    "\n",
    "You will find cells which contain the comment % GRADED FUNCTION: functionName. Do not edit that comment. Those cells will be used to grade your assignment. Each block of code with that comment should only have the function. \n",
    "\n",
    "Instructions will be provided as needed in the exercise. \n",
    "\n",
    "\n",
    "#### After submitting your assignment, you can [check your grades here](https://www.coursera.org/learn/ml-test-jupyter/programming/oO6Vo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines\n",
    "=======================\n",
    "\n",
    "In the first half of this exercise, you will be using support vector\n",
    "machines (SVMs) with various example 2D datasets. Experimenting with\n",
    "these datasets will help you gain an intuition of how SVMs work and how\n",
    "to use a Gaussian kernel with SVMs. In the next half of the exercise,\n",
    "you will be using support vector machines to build a spam classifier.\n",
    "\n",
    "Example Dataset 1\n",
    "-----------------\n",
    "\n",
    "We will begin with a 2D example dataset which can be separated by a\n",
    "linear boundary. We will plot the training data for you\n",
    "(Figure 1). In this dataset, the positions of the\n",
    "positive examples (indicated with $+$) and the negative examples\n",
    "(indicated with $o$) suggest a natural separation indicated by the gap.\n",
    "However, notice that there is an outlier positive example $+$ on the far\n",
    "left at about $(0.1,4.1)$. In this exercise you will see\n",
    "how this outlier affects the SVM decision boundary.\n",
    "\n",
    "<img src=\"figure 1.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "\n",
    "\n",
    "You will also try using different values of the\n",
    "$C$ parameter with SVMs. Informally, the $C$ parameter is a positive\n",
    "value that controls the penalty for misclassified training examples. A\n",
    "large $C$ parameter tells the SVM to try to classify all the examples\n",
    "correctly. $C$ plays a role similar to $\\frac{1}{\\lambda}$, where\n",
    "$\\lambda$ is the regularization parameter that we were using previously\n",
    "for logistic regression.\n",
    "\n",
    "<table><tr><td><img src=\"figure 2.png\" width=\"450\" height=\"450\"></td><td><img src=\"figure 3.png\" width=\"450\" height=\"450\"></td></tr></table>\n",
    "\n",
    "Then, you will run the SVM training (with $C=1$)\n",
    "using SVM software that we have included with the starter code in **svmTrain**. \n",
    "\n",
    "When $C=1$, you should find that the SVM puts the\n",
    "decision boundary in the gap between the two datasets and\n",
    "*misclassifies* the data point on the far left (Figure 2).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation Note:** Most SVM software packages (including\n",
    "**svmTrain** automatically add the extra feature $x_0=1$ for you\n",
    "and automatically take care of learning the intercept term $\\theta_0$.\n",
    "So when passing your training data to the SVM software, there is no need\n",
    "to add this extra feature $x_0=1$ yourself. In particular, in\n",
    "Octave/MATLAB your code should be working with training examples\n",
    "$x\\in \\Re^n$ (rather than $x \\in \\Re^{n+1})$; for example, in the first\n",
    "example dataset $x \\in \\Re^2$.\n",
    "\n",
    "Your task is to try different values of $C$ on this dataset. Specifically,\n",
    "you should change the value of $C$ in the script to $C=100$ and run the SVM training \n",
    "again. When $C=100$, you should find that the SVM now classifies every single\n",
    "example correctly, but has a decision boundary that does not appear to be a \n",
    "natural fit for the data (Figure 3). \n",
    "\n",
    "You should experiment below with different values of C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load('ex6data1.mat');                       % Loading the Data ... provides you with X and y in your environment\n",
    "plotData(X, y);                             % Plot training data\n",
    "\n",
    "C = 100;\n",
    "model = svmTrain(X, y, C, @linearKernel, 1e-3, 20);         % Training the linear SVM \n",
    "visualizeBoundaryLinear(X, y, model);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with Gaussian Kernels\n",
    "-------------------------\n",
    "\n",
    "Now we will use SVMs to do non-linear\n",
    "classification. In particular, you will be using SVMs with Gaussian\n",
    "kernels on datasets that are not linearly separable.\n",
    "\n",
    "### Gaussian Kernel\n",
    "\n",
    "To find non-linear decision boundaries with the SVM, we need to first\n",
    "implement a Gaussian kernel. You can think of the Gaussian kernel as a\n",
    "similarity function that measures the “distance” between a pair of\n",
    "examples, ($x^{(i)},x^{(j)}$). The Gaussian kernel is also parameterized\n",
    "by a bandwidth parameter, $\\sigma$, which determines how fast the\n",
    "similarity metric decreases (to 0) as the examples are further apart.\n",
    "\n",
    "You should now complete the code in the **gaussianKernel** function to compute\n",
    "the Gaussian kernel between two examples, ($x^{(i)},x^{(j)}$). The\n",
    "Gaussian kernel function is defined as:\n",
    "\n",
    "$$K_{gaussian}(x^{(i)},x^{(j)}) = \n",
    "\\mathrm{exp}\\left(- \\;\\frac{\\| x^{(i)} - x^{(j)}\\|^2}{2\\sigma^2}\\right) =\n",
    "\\mathrm{exp}\\left(- \\;\\frac{\\sum\\limits_{k=1}^{n} (x_k^{(i)} - x_k^{(j)})^2}{2\\sigma^2}\\right)\\tag{1}$$\n",
    "\n",
    "Once you’ve completed the function **gaussianKernel**, run the cell under it to test your kernel function on two provided examples. \n",
    "\n",
    "**Implementtion:**\n",
    "\n",
    "**sim = gaussianKernel(x1, x2)** returns a gaussian kernel between $x^{(1)}$ and $x^{(2)}$\n",
    "and returns the value in sim. Make sure that $x^{(1)}$ and $x^{(2)}$ are column vectors. You should fill in this function to return the similarity between $x^{(1)}$ and $x^{(2)}$ computed using a Gaussian kernel with bandwidth sigma. Set sim to equation 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: gaussianKernel\n",
    "function sim = gaussianKernel(x1, x2, sigma)\n",
    "x1 = x1(:); x2 = x2(:);\n",
    "sim = 0;                         % Return the following variable correctly.\n",
    "\n",
    "% ============ YOUR CODE HERE ============\n",
    "\n",
    "\n",
    "\n",
    "% ========================================\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x1 = [1 2 1]; x2 = [0 4 -1]; sigma = 2;\n",
    "sim = gaussianKernel(x1, x2, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "0.32465"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset 2\n",
    "\n",
    "<img src=\"figure 4.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "Now we will plot dataset 2 (Figure 4). From the figure, you can obserse that there is no\n",
    "linear decision boundary that separates the positive and negative\n",
    "examples for this dataset. However, by using the Gaussian kernel with\n",
    "the SVM, you will be able to learn a non-linear decision boundary that\n",
    "can perform reasonably well for the dataset.\n",
    "\n",
    "If you have correctly implemented the Gaussian kernel function above we will proceed to train the SVM with the Gaussian kernel on\n",
    "this dataset. \n",
    "\n",
    "<img src=\"figure 5.png\" width=\"550\" height=\"550\">\n",
    "\n",
    "Figure **5** shows the decision boundary found\n",
    "by the SVM with a Gaussian kernel. The decision boundary is able to\n",
    "separate most of the positive and negative examples correctly and\n",
    "follows the contours of the dataset well.\n",
    "\n",
    "**Note**:  We set the tolerance and max_passes lower here so that the code will run faster. However, in practice, you will want to run the training to convergence.\n",
    "\n",
    "Run the cell below to visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fprintf('\\nTraining SVM with RBF Kernel (this may take 1 to 2 minutes) ...\\n');\n",
    "load('ex6data2.mat');                         % Loading Data... you will have X and y in your workspace\n",
    "C = 1; sigma = 0.1;                           % SVM Parameters\n",
    "\n",
    "model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma)); % Training your SVM\n",
    "visualizeBoundary(X, y, model);    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Dataset 3\n",
    "\n",
    "Now, you will gain more practical skills on how\n",
    "to use a SVM with a Gaussian kernel. The next part of the exercise will\n",
    "load and display a third dataset (Figure 6). You will\n",
    "be using the SVM with the Gaussian kernel with this dataset.\n",
    "\n",
    "<img src=\"figure 6.png\" width=\"450\" height=\"450\">\n",
    "\n",
    "In the provided dataset, **ex6data3.mat**, you are given the\n",
    "variables $X$, $y$, $Xval$, $yval$. The provided code below\n",
    "trains the SVM classifier using the training set $X$, $y$ using\n",
    "parameters loaded from dataset3Params.\n",
    "\n",
    "You could plot the data to see a similar image. Run the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load('ex6data3.mat');         % Loading Data... you will have X and y in your workspace\n",
    "plotData(X, y);               % Plot training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to use the cross validation set $Xval$, $yval$ to\n",
    "determine the best $C$ and $\\sigma$ parameter to use. You should train your model using svmTrain with the training data and you should test it using the validation data. You should write\n",
    "any additional code necessary to help you search over the parameters $C$\n",
    "and $\\sigma$. For *both* $C$ and $\\sigma$, we suggest trying values in\n",
    "multiplicative steps (e.g., $0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30$). Note\n",
    "that you should try all possible pairs of values for $C$ and $\\sigma$\n",
    "(e.g., $C=0.3$ and $\\sigma=0.1$). For example, if you try each of the 8\n",
    "values listed above for $C$ and for $\\sigma^2$, you would end up\n",
    "training and evaluating (on the cross validation set) a total of\n",
    "$8^2 = 64$ different models.\n",
    "\n",
    "<img src=\"figure 7.png\" width=\"550\" height=\"550\">\n",
    "\n",
    "After you have determined the best $C$ and $\\sigma$ parameters to use,\n",
    "you should modify the code in **dataset3Params** (below), filling in the\n",
    "best parameters you found. For our best parameters, the SVM returned a decision boundary shown in Figure 7.\n",
    "\n",
    "**Implementation**:\n",
    "\n",
    "**[C, sigma] = dataset3Params(X, y, Xval, yval)** returns your choice of C and sigma. You should complete this function to return the optimal C and sigma based on a cross-validation set. Fill in the function below to return the optimal C and sigma learning parameters found using the cross validation set. You can use svmPredict to predict the labels on the cross validation set. For example, predictions = svmPredict(model, Xval); will return the predictions on the cross validation set.  \n",
    " \n",
    "When implementing cross validation to select the best C and parameter to use, you need to evaluate the error on the cross validation set. Recall that for classification, the error is defined as the fraction of the cross validation examples that were classified incorrectly. In Octave/MATLAB, you can compute this error using mean(double(predictions ~= yval)), where predictions is a vector containing all the predictions from the SVM, and yval are the true labels from the cross validation set. You can use the svmPredict function to generate the predictions for the cross validation set. You could also have something like C_list = [0 0.1 0.03...] and s_list = [0.01 0.03...] to try out different values. You could use a nested forloop to evaluate all possible combinations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% GRADED FUNCTION: dataset3Params\n",
    "function [C, sigma] = dataset3Params(X, y, Xval, yval)\n",
    "\n",
    "C = 1;                           % You need to return the following variables correctly.\n",
    "sigma = 0.3;\n",
    "\n",
    "% ====================== YOUR CODE HERE ======================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "% ============================================================\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "% Try different values of C and sigma here.\n",
    "load('ex6data3.mat');                                                 % Reloading the data\n",
    "[C, sigma] = dataset3Params(X, y, Xval, yval);                        % Try different SVM Parameters here\n",
    "model= svmTrain(X, y, C, @(x1, x2) gaussianKernel(x1, x2, sigma));    % Train the SVM\n",
    "visualizeBoundary(X, y, model);"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "ml-test-jupyter",
   "graded_item_id": "oO6Vo",
   "launcher_item_id": "CIuTt",
   "submission_attachments": [
    "computeCost.m",
    "computeCostMulti.m",
    "featureNormalize.m",
    "gradientDescent.m",
    "gradientDescentMulti.m",
    "normalEqn.m",
    "plotData.m",
    "warmUpExercise.m"
   ]
  },
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
